{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bank Marketing Data Set\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/Bank+Marketing\n",
    "\n",
    "The data is related with direct marketing campaigns (phone calls) of a Portuguese banking institution.\n",
    "The classification goal is to predict if the client will subscribe a term deposit (variable y).\n",
    "\n",
    "download this:\n",
    "https://archive.ics.uci.edu/ml/machine-learning-databases/00222/bank-additional.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Data sets\n",
    "# http://archive.ics.uci.edu/ml/datasets/Bank+Marketing\n",
    "folder = \"data/bank-additional/bank-additional/\"\n",
    "bank_train_file = folder + \"bank-additional-full.csv\"\n",
    "bank_test_file = folder + \"bank-additional.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loading and proccessing data usnig pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age        job  marital    education  default housing loan    contact  \\\n",
       "0   56  housemaid  married     basic.4y       no      no   no  telephone   \n",
       "1   57   services  married  high.school  unknown      no   no  telephone   \n",
       "2   37   services  married  high.school       no     yes   no  telephone   \n",
       "3   40     admin.  married     basic.6y       no      no   no  telephone   \n",
       "4   56   services  married  high.school       no      no  yes  telephone   \n",
       "\n",
       "  month day_of_week ...  campaign  pdays  previous     poutcome emp.var.rate  \\\n",
       "0   may         mon ...         1    999         0  nonexistent          1.1   \n",
       "1   may         mon ...         1    999         0  nonexistent          1.1   \n",
       "2   may         mon ...         1    999         0  nonexistent          1.1   \n",
       "3   may         mon ...         1    999         0  nonexistent          1.1   \n",
       "4   may         mon ...         1    999         0  nonexistent          1.1   \n",
       "\n",
       "   cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n",
       "0          93.994          -36.4      4.857       5191.0  no  \n",
       "1          93.994          -36.4      4.857       5191.0  no  \n",
       "2          93.994          -36.4      4.857       5191.0  no  \n",
       "3          93.994          -36.4      4.857       5191.0  no  \n",
       "4          93.994          -36.4      4.857       5191.0  no  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_train = pd.read_csv(bank_train_file,sep=\";\")\n",
    "pd_test = pd.read_csv(bank_test_file,sep=\";\")\n",
    "pd_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((41188, 21), (4119, 21))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_train.shape, pd_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# clean and arrange data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age        job  marital    education default housing loan    contact month  \\\n",
       "0   56  housemaid  married     basic.4y      no      no   no  telephone   may   \n",
       "1   57   services  married  high.school     NaN      no   no  telephone   may   \n",
       "2   37   services  married  high.school      no     yes   no  telephone   may   \n",
       "3   40     admin.  married     basic.6y      no      no   no  telephone   may   \n",
       "4   56   services  married  high.school      no      no  yes  telephone   may   \n",
       "\n",
       "  day_of_week ...  campaign  pdays  previous  poutcome emp.var.rate  \\\n",
       "0         mon ...         1    NaN         0       NaN          1.1   \n",
       "1         mon ...         1    NaN         0       NaN          1.1   \n",
       "2         mon ...         1    NaN         0       NaN          1.1   \n",
       "3         mon ...         1    NaN         0       NaN          1.1   \n",
       "4         mon ...         1    NaN         0       NaN          1.1   \n",
       "\n",
       "   cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n",
       "0          93.994          -36.4      4.857       5191.0  no  \n",
       "1          93.994          -36.4      4.857       5191.0  no  \n",
       "2          93.994          -36.4      4.857       5191.0  no  \n",
       "3          93.994          -36.4      4.857       5191.0  no  \n",
       "4          93.994          -36.4      4.857       5191.0  no  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_train = pd.read_csv(bank_train_file,sep=\";\",na_values=[\"unknown\",\"nonexistent\",\"999\"])\n",
    "pd_test = pd.read_csv(bank_test_file,sep=\";\",na_values=[\"unknown\",\"nonexistent\",\"999\"])\n",
    "pd_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fixed_data(pd_data) :\n",
    "    # fix labels\n",
    "    pd_data['y'] = pd_data['y'].replace(to_replace=dict(no=0, yes=1))\n",
    "    \n",
    "    # drop duration zero rows\n",
    "    pd_data = pd_data[pd_data['duration'] > 0.0]\n",
    "    \n",
    "    #transform categorical text columns to numerics\n",
    "    cols_to_transform_to_numerics = [ 'job','marital','education','default','housing','loan',\n",
    "                     'contact','month','day_of_week','poutcome' ]\n",
    "    file_data_numerics = pd.get_dummies(data=pd_data, columns = cols_to_transform_to_numerics)\n",
    "    \n",
    "    #fill the rest columns na values with zeros\n",
    "    file_data_numerics_no_na = file_data_numerics.fillna(0)\n",
    "    \n",
    "    #normalized the rest numeric columns\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    file_data_normalized = min_max_scaler.fit_transform(file_data_numerics_no_na.values)\n",
    "    \n",
    "    # add bias\n",
    "    #num_rows = file_data_normalized.shape[0]\n",
    "    #file_data_normalized_bias = np.c_[np.ones((num_rows, 1)), file_data_normalized]\n",
    "    \n",
    "    # return pandas DataFrame\n",
    "    full_data = pd.DataFrame(file_data_normalized)\n",
    "    \n",
    "    return full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.052878</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.698753</td>\n",
       "      <td>0.60251</td>\n",
       "      <td>0.957379</td>\n",
       "      <td>0.859735</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.493827</td>\n",
       "      <td>0.030100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.698753</td>\n",
       "      <td>0.60251</td>\n",
       "      <td>0.957379</td>\n",
       "      <td>0.859735</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.246914</td>\n",
       "      <td>0.045760</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.698753</td>\n",
       "      <td>0.60251</td>\n",
       "      <td>0.957379</td>\n",
       "      <td>0.859735</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.283951</td>\n",
       "      <td>0.030506</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.698753</td>\n",
       "      <td>0.60251</td>\n",
       "      <td>0.957379</td>\n",
       "      <td>0.859735</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.062233</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.698753</td>\n",
       "      <td>0.60251</td>\n",
       "      <td>0.957379</td>\n",
       "      <td>0.859735</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1    2    3    4       5         6        7         8   \\\n",
       "0  0.481481  0.052878  0.0  0.0  0.0  0.9375  0.698753  0.60251  0.957379   \n",
       "1  0.493827  0.030100  0.0  0.0  0.0  0.9375  0.698753  0.60251  0.957379   \n",
       "2  0.246914  0.045760  0.0  0.0  0.0  0.9375  0.698753  0.60251  0.957379   \n",
       "3  0.283951  0.030506  0.0  0.0  0.0  0.9375  0.698753  0.60251  0.957379   \n",
       "4  0.481481  0.062233  0.0  0.0  0.0  0.9375  0.698753  0.60251  0.957379   \n",
       "\n",
       "         9  ...    47   48   49   50   51   52   53   54   55   56  \n",
       "0  0.859735 ...   0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1  0.859735 ...   0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2  0.859735 ...   0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3  0.859735 ...   0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4  0.859735 ...   0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_train_fixed = get_fixed_data(pd_train)\n",
    "pd_test_fixed = get_fixed_data(pd_test)\n",
    "pd_train_fixed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before train, test: (41188, 21) (4119, 21)\n",
      "after train, test: (41182, 57) (4117, 57)\n"
     ]
    }
   ],
   "source": [
    "print(\"before train, test:\",pd_train.shape, pd_test.shape)\n",
    "print(\"after train, test:\",pd_train_fixed.shape, pd_test_fixed.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split to train validate and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (37159, 56) (37159,)\n",
      "Validation set (4023, 56) (4023,)\n",
      "Test set (4117, 56) (4117,)\n"
     ]
    }
   ],
   "source": [
    "msk = np.random.rand(len(pd_train_fixed)) < 0.9\n",
    "\n",
    "train = pd_train_fixed[msk]\n",
    "valid = pd_train_fixed[~msk]\n",
    "test = pd_test_fixed\n",
    "\n",
    "idx_label = pd_train_fixed.shape[1]-1\n",
    "\n",
    "pd_train_labels = train[idx_label]\n",
    "pd_train_data = train.drop(idx_label,axis=1)\n",
    "\n",
    "pd_valid_labels = valid[idx_label]\n",
    "pd_valid_data = valid.drop(idx_label,axis=1)\n",
    "\n",
    "pd_test_labels = pd_test_fixed[idx_label]\n",
    "pd_test_data = pd_test_fixed.drop(idx_label,axis=1)\n",
    "\n",
    "print('Training set', pd_train_data.shape, pd_train_labels.shape)\n",
    "print('Validation set', pd_valid_data.shape, pd_valid_labels.shape)\n",
    "print('Test set', pd_test_data.shape, pd_test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd_train_data.values\n",
    "train_labels = pd_train_labels.values.reshape(-1,1)\n",
    "\n",
    "valid_data = pd_valid_data.values\n",
    "valid_labels = pd_valid_labels.values.reshape(-1,1)\n",
    "\n",
    "test_data = pd_test_data.values\n",
    "test_labels = pd_test_labels.values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# start tensorflow algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that extarct the accuracy percents\n",
    "def accuracy(predictions, labels):\n",
    "    predicted_class = tf.greater(predictions,0.5)\n",
    "    correct = tf.equal(predicted_class, tf.equal(labels,1.0))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, 'float')) * 100\n",
    "    return accuracy.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# without regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "num_rows = train_data.shape[0]\n",
    "num_cols = train_data.shape[1]\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    X = tf.placeholder(tf.float32,[None, num_cols], name=\"X\")\n",
    "    Y = tf.placeholder(tf.float32, [None, 1], name=\"Y\")\n",
    "    L_rate = tf.placeholder(tf.float32, name=\"L_rate\")    \n",
    "    \n",
    "    tf_valid_data = tf.constant(valid_data, dtype=tf.float32)\n",
    "    tf_test_data = tf.constant(test_data, dtype=tf.float32)\n",
    "\n",
    "    weights = tf.Variable(tf.random_uniform([num_cols, 1], -1.0, 1.0, seed=42), name=\"weights\")\n",
    "    B = tf.placeholder(tf.float32, [None,1])\n",
    "    \n",
    "    y_pred = tf.matmul(X, weights) + B\n",
    "    loss = tf.reduce_mean(y_pred - Y, name=\"loss\")\n",
    "    \n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=L_rate).minimize(loss) \n",
    "    \n",
    "    train_prediction = y_pred\n",
    "    \n",
    "    valid_bias = tf.ones([valid_data.shape[0],1],dtype=np.float32)\n",
    "    valid_prediction = tf.matmul(tf_valid_data, weights) + valid_bias\n",
    "    \n",
    "    test_bias = tf.ones([test_data.shape[0],1],dtype=np.float32)\n",
    "    test_prediction = tf.matmul(tf_test_data, weights) + test_bias\n",
    "    \n",
    "    init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b_size: 1000, l_rate:0.001, epoch:    0:,loss: 0.258982, tr_accuracy: 57.9%, valid_accuracy: 66.3%\n",
      "b_size: 1000, l_rate:0.001, epoch: 1000:,loss: -7.014723, tr_accuracy: 99.6%, valid_accuracy: 96.7%\n",
      "b_size: 1000, l_rate:0.001, epoch: 2000:,loss: -12.335945, tr_accuracy: 100.0%, valid_accuracy: 96.7%\n",
      "b_size: 1000, l_rate:0.001, epoch: 3000:,loss: -14.397912, tr_accuracy: 69.6%, valid_accuracy: 96.7%\n",
      "learning_rate:0.001, Test accuracy: 96.6%\n",
      "b_size: 1000, l_rate:0.010, epoch:    0:,loss: 0.258982, tr_accuracy: 57.9%, valid_accuracy: 68.3%\n",
      "b_size: 1000, l_rate:0.010, epoch: 1000:,loss: -59.227299, tr_accuracy: 99.6%, valid_accuracy: 96.7%\n",
      "b_size: 1000, l_rate:0.010, epoch: 2000:,loss: -126.021484, tr_accuracy: 100.0%, valid_accuracy: 96.7%\n",
      "b_size: 1000, l_rate:0.010, epoch: 3000:,loss: -140.366333, tr_accuracy: 69.6%, valid_accuracy: 96.7%\n",
      "learning_rate:0.010, Test accuracy: 96.6%\n",
      "b_size: 1000, l_rate:0.100, epoch:    0:,loss: 0.258982, tr_accuracy: 57.9%, valid_accuracy: 83.3%\n",
      "b_size: 1000, l_rate:0.100, epoch: 1000:,loss: -581.351807, tr_accuracy: 99.6%, valid_accuracy: 96.7%\n",
      "b_size: 1000, l_rate:0.100, epoch: 2000:,loss: -1262.874512, tr_accuracy: 100.0%, valid_accuracy: 96.7%\n",
      "b_size: 1000, l_rate:0.100, epoch: 3000:,loss: -1400.048950, tr_accuracy: 69.6%, valid_accuracy: 96.7%\n",
      "learning_rate:0.100, Test accuracy: 96.6%\n",
      "optimizer finished\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "learning_rates = [0.001,0.01,0.1]\n",
    "batch_sizes = [1000]\n",
    "batch_size = 10000\n",
    "n_epochs = 3001\n",
    "\n",
    "for l_rate in learning_rates:\n",
    "    for batch_size in batch_sizes:\n",
    "        with tf.Session(graph=graph) as sess:\n",
    "            sess.run(init)\n",
    "            saver = tf.train.Saver()\n",
    "        \n",
    "            for epoch in range(n_epochs):\n",
    "                offset = (epoch * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "                batch_data = train_data[offset:(offset + batch_size), :]\n",
    "                batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "                \n",
    "                bias = np.ones([batch_size,1],dtype=np.float32)\n",
    "                \n",
    "                feed_dict = {X: batch_data, Y: batch_labels, B: bias, L_rate: l_rate}\n",
    "                o, loss_val, predictions = sess.run([optimizer, loss, train_prediction], feed_dict=feed_dict )\n",
    "                \n",
    "                if epoch % 1000 == 0:\n",
    "                    save_path = saver.save(sess, folder + \"tmp/bank_marketing.ckpt\")\n",
    "                    train_accuracy = accuracy(predictions, batch_labels)\n",
    "                    validation_accuracy = accuracy(valid_prediction.eval(), valid_labels)\n",
    "                    print(\"b_size:%5d, l_rate:%.3f, epoch: %4d:,loss: %f, tr_accuracy: %.1f%%, valid_accuracy: %.1f%%\" % \\\n",
    "                          (batch_size,l_rate,epoch,loss_val,train_accuracy,validation_accuracy))\n",
    "        \n",
    "            save_path = saver.save(sess, folder + \"tmp/bank_marketing_final.ckpt\")\n",
    "            \n",
    "            test_accuracy = accuracy(test_prediction.eval(), test_labels)\n",
    "            print(\"learning_rate:%.3f, Test accuracy: %.1f%%\" % (l_rate,test_accuracy))\n",
    "        \n",
    "print(\"optimizer finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L1 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variable_summaries(var):\n",
    "    with tf.name_scope('summaries'):\n",
    "        mean = tf.reduce_mean(var)\n",
    "        tf.summary.scalar('mean', mean)\n",
    "        with tf.name_scope('stddev'):\n",
    "            stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n",
    "        tf.summary.scalar('stddev', stddev)\n",
    "        tf.summary.scalar('max', tf.reduce_max(var))\n",
    "        tf.summary.scalar('min', tf.reduce_min(var))\n",
    "        tf.summary.histogram('histogram', var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "num_hidden_nodes = 10\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    X = tf.placeholder(tf.float32,[None, num_cols], name=\"X\")\n",
    "    Y = tf.placeholder(tf.float32, [None, 1], name=\"Y\")\n",
    "    L_rate = tf.placeholder(tf.float32, name=\"L_rate\")    \n",
    "    \n",
    "    tf_valid_data = tf.constant(valid_data, dtype=tf.float32)\n",
    "    tf_test_data = tf.constant(test_data, dtype=tf.float32)\n",
    "\n",
    "    weights = tf.Variable(tf.random_uniform([num_cols, 1], -1.0, 1.0, seed=42), name=\"weights\")\n",
    "    B = tf.placeholder(tf.float32, [None,1])\n",
    "    \n",
    "    y_pred = tf.add(tf.matmul(X, weights), B)\n",
    "    loss = tf.reduce_mean(np.abs(y_pred - Y), name=\"loss\")\n",
    "    \n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=L_rate).minimize(loss) \n",
    "    \n",
    "    train_prediction = y_pred\n",
    "    \n",
    "    valid_bias = tf.ones([valid_data.shape[0],1],dtype=np.float32)\n",
    "    valid_prediction = tf.matmul(tf_valid_data, weights) + valid_bias\n",
    "    \n",
    "    test_bias = tf.ones([test_data.shape[0],1],dtype=np.float32)\n",
    "    test_prediction = tf.matmul(tf_test_data, weights) + test_bias\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    # Create a summary to monitor cost tensor\n",
    "    tf.summary.scalar(\"loss\", loss)\n",
    "    # Merge all summaries into a single op\n",
    "    merged_summary_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b_size:10000, l_rate:0.010, epoch:    0:,loss: 0.762415, tr_accuracy: 67.6%, valid_accuracy: 66.3%\n",
      "b_size:10000, l_rate:0.010, epoch: 1000:,loss: 0.172847, tr_accuracy: 95.8%, valid_accuracy: 91.1%\n",
      "b_size:10000, l_rate:0.010, epoch: 2000:,loss: 0.073958, tr_accuracy: 97.4%, valid_accuracy: 92.8%\n",
      "b_size:10000, l_rate:0.010, epoch: 3000:,loss: 0.059495, tr_accuracy: 96.3%, valid_accuracy: 94.9%\n",
      "b_size:10000, l_rate:0.010, epoch: 4000:,loss: 0.078279, tr_accuracy: 95.9%, valid_accuracy: 96.5%\n",
      "b_size:10000, l_rate:0.010, epoch: 5000:,loss: 0.055268, tr_accuracy: 99.9%, valid_accuracy: 96.3%\n",
      "b_size:10000, l_rate:0.010, epoch: 6000:,loss: 0.020257, tr_accuracy: 99.9%, valid_accuracy: 96.6%\n",
      "b_size:10000, l_rate:0.010, epoch: 7000:,loss: 0.032206, tr_accuracy: 99.9%, valid_accuracy: 96.6%\n",
      "b_size:10000, l_rate:0.010, epoch: 8000:,loss: 0.040170, tr_accuracy: 99.3%, valid_accuracy: 96.6%\n",
      "learning_rate:0.010, Test accuracy: 96.2%\n",
      "optimizer finished\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "learning_rates = [0.01]\n",
    "batch_sizes = [10000]\n",
    "batch_size = 10000\n",
    "n_epochs = 8001\n",
    "\n",
    "logs_path = folder + '/tmp/tensorflow_logs/2_layer/'\n",
    "\n",
    "for l_rate in learning_rates:\n",
    "    for batch_size in batch_sizes:\n",
    "        with tf.Session(graph=graph) as sess:\n",
    "            sess.run(init)\n",
    "            saver = tf.train.Saver()\n",
    "            \n",
    "            # op to write logs to Tensorboard\n",
    "            summary_writer = tf.summary.FileWriter(logs_path, graph=graph)\n",
    "            \n",
    "            for epoch in range(n_epochs):\n",
    "                offset = (epoch * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "                batch_data = train_data[offset:(offset + batch_size), :]\n",
    "                batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "                \n",
    "                bias = np.ones([batch_size,1],dtype=np.float32)\n",
    "                \n",
    "                feed_dict = {X: batch_data, Y: batch_labels, B: bias, L_rate: l_rate}\n",
    "                o, loss_val, predictions,summary = sess.run([optimizer, loss, train_prediction,merged_summary_op], feed_dict=feed_dict )\n",
    "                \n",
    "                # Write logs at every iteration\n",
    "                summary_writer.add_summary(summary, epoch)\n",
    "                \n",
    "                if epoch % 1000 == 0:\n",
    "                    save_path = saver.save(sess, folder + \"tmp/bank_marketing.ckpt\")\n",
    "                    train_accuracy = accuracy(predictions, batch_labels)\n",
    "                    validation_accuracy = accuracy(valid_prediction.eval(), valid_labels)\n",
    "                    print(\"b_size:%5d, l_rate:%.3f, epoch: %4d:,loss: %f, tr_accuracy: %.1f%%, valid_accuracy: %.1f%%\" % \\\n",
    "                          (batch_size,l_rate,epoch,loss_val,train_accuracy,validation_accuracy))\n",
    "        \n",
    "            best_weights = weights.eval()\n",
    "            save_path = saver.save(sess, folder + \"tmp/bank_marketing_final.ckpt\")\n",
    "            \n",
    "            test_accuracy = accuracy(test_prediction.eval(), test_labels)\n",
    "            print(\"learning_rate:%.3f, Test accuracy: %.1f%%\" % (l_rate,test_accuracy))\n",
    "        \n",
    "print(\"optimizer finished\")\n",
    "\n",
    "# Merge all summaries into a single op\n",
    "merged_summary_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L2 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "num_labels = 1\n",
    "num_hidden_nodes = 10\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    X = tf.placeholder(tf.float32,[None, num_cols], name=\"X\")\n",
    "    Y = tf.placeholder(tf.float32, [None, 1], name=\"Y\")\n",
    "    L_rate = tf.placeholder(tf.float32, name=\"L_rate\")    \n",
    "    Beta_regul = tf.placeholder(tf.float32)\n",
    "    X_labels = tf.placeholder(tf.float32, shape=(None, num_labels))\n",
    "    \n",
    "    tf_valid_data = tf.constant(valid_data, dtype=tf.float32)\n",
    "    tf_test_data = tf.constant(test_data, dtype=tf.float32)\n",
    "\n",
    "    # Variables.\n",
    "    weights1 = tf.Variable(tf.truncated_normal([num_cols, num_hidden_nodes]))\n",
    "    biases1 = tf.Variable(tf.ones([num_hidden_nodes]))\n",
    "    weights2 = tf.Variable(tf.truncated_normal([num_hidden_nodes, num_labels]))\n",
    "    biases2 = tf.Variable(tf.ones([num_labels]))\n",
    "  \n",
    "    # Training computation.\n",
    "    lay1_train = tf.nn.relu(tf.matmul(X, weights1) + biases1)\n",
    "    y_pred = tf.matmul(lay1_train, weights2) + biases2\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_pred, labels=X_labels))\n",
    "    \n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=L_rate).minimize(loss) \n",
    "    \n",
    "    train_prediction = tf.nn.softmax(y_pred)\n",
    "    \n",
    "    lay1_valid = tf.nn.relu(tf.matmul(tf_valid_data, weights1) + biases1)\n",
    "    valid_prediction = tf.nn.softmax(tf.matmul(lay1_valid, weights2) + biases2)\n",
    "    \n",
    "    lay1_test = tf.nn.relu(tf.matmul(tf_test_data, weights1) + biases1)\n",
    "    test_prediction = tf.nn.softmax(tf.matmul(lay1_test, weights2) + biases2)\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b_size:10000, l_rate:0.010, epoch:    0:,loss: 0.000000, tr_accuracy: 0.0%, valid_accuracy: 3.3%\n",
      "b_size:10000, l_rate:0.010, epoch: 1000:,loss: 0.000000, tr_accuracy: 0.3%, valid_accuracy: 3.3%\n",
      "b_size:10000, l_rate:0.010, epoch: 2000:,loss: nan, tr_accuracy: 100.0%, valid_accuracy: 96.7%\n",
      "b_size:10000, l_rate:0.010, epoch: 3000:,loss: nan, tr_accuracy: 99.4%, valid_accuracy: 96.7%\n",
      "learning_rate:0.010, Test accuracy: 96.6%\n",
      "optimizer finished\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "learning_rates = [0.01]\n",
    "batch_sizes = [10000]\n",
    "n_epochs = 3001\n",
    "\n",
    "for l_rate in learning_rates:\n",
    "    for batch_size in batch_sizes:\n",
    "        with tf.Session(graph=graph) as sess:\n",
    "            sess.run(init)\n",
    "            saver = tf.train.Saver()\n",
    "        \n",
    "            for epoch in range(n_epochs):\n",
    "                offset = (epoch * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "                batch_data = train_data[offset:(offset + batch_size), :]\n",
    "                batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "                \n",
    "                bias = np.ones([batch_size,1],dtype=np.float32)\n",
    "                \n",
    "                feed_dict = {X: batch_data, Y: batch_labels, L_rate: l_rate, \n",
    "                             X_labels: batch_labels}\n",
    "                o, loss_val, predictions = sess.run([optimizer, loss, train_prediction], feed_dict=feed_dict )\n",
    "                \n",
    "                if epoch % 1000 == 0:\n",
    "                    save_path = saver.save(sess, folder + \"tmp/bank_marketing.ckpt\")\n",
    "                    train_accuracy = accuracy(predictions, batch_labels)\n",
    "                    validation_accuracy = accuracy(valid_prediction.eval(), valid_labels)\n",
    "                    print(\"b_size:%5d, l_rate:%.3f, epoch: %4d:,loss: %f, tr_accuracy: %.1f%%, valid_accuracy: %.1f%%\" % \\\n",
    "                          (batch_size,l_rate,epoch,loss_val,train_accuracy,validation_accuracy))\n",
    "        \n",
    "            save_path = saver.save(sess, folder + \"tmp/bank_marketing_final.ckpt\")\n",
    "            \n",
    "            test_accuracy = accuracy(test_prediction.eval(), test_labels)\n",
    "            print(\"learning_rate:%.3f, Test accuracy: %.1f%%\" % (l_rate,test_accuracy))\n",
    "        \n",
    "print(\"optimizer finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L2 regularization with dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "num_labels = 1\n",
    "num_hidden_nodes = 10\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    X = tf.placeholder(tf.float32,[None, num_cols], name=\"X\")\n",
    "    Y = tf.placeholder(tf.float32, [None, 1], name=\"Y\")\n",
    "    L_rate = tf.placeholder(tf.float32, name=\"L_rate\")    \n",
    "    Beta_regul = tf.placeholder(tf.float32)\n",
    "    X_labels = tf.placeholder(tf.float32, shape=(None, num_labels))\n",
    "    \n",
    "    tf_valid_data = tf.constant(valid_data, dtype=tf.float32)\n",
    "    tf_test_data = tf.constant(test_data, dtype=tf.float32)\n",
    "\n",
    "    # Variables.\n",
    "    weights1 = tf.Variable(tf.truncated_normal([num_cols, num_hidden_nodes]))\n",
    "    biases1 = tf.Variable(tf.ones([num_hidden_nodes]))\n",
    "    weights2 = tf.Variable(tf.truncated_normal([num_hidden_nodes, num_labels]))\n",
    "    biases2 = tf.Variable(tf.ones([num_labels]))\n",
    "  \n",
    "    # Training computation.\n",
    "    lay1_train = tf.nn.relu(tf.matmul(X, weights1) + biases1)\n",
    "    drop1 = tf.nn.dropout(lay1_train, 0.5)\n",
    "    y_pred = tf.matmul(drop1, weights2) + biases2\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_pred, labels=X_labels))\n",
    "    \n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=L_rate).minimize(loss) \n",
    "    \n",
    "    train_prediction = tf.nn.softmax(y_pred)\n",
    "    \n",
    "    lay1_valid = tf.nn.relu(tf.matmul(tf_valid_data, weights1) + biases1)\n",
    "    valid_prediction = tf.nn.softmax(tf.matmul(lay1_valid, weights2) + biases2)\n",
    "    \n",
    "    lay1_test = tf.nn.relu(tf.matmul(tf_test_data, weights1) + biases1)\n",
    "    test_prediction = tf.nn.softmax(tf.matmul(lay1_test, weights2) + biases2)\n",
    "    \n",
    "    init = tf.global_variables_initializer()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b_size:10000, l_rate:0.010, epoch:    0:,loss: 0.000000, tr_accuracy: 0.0%, valid_accuracy: 3.3%\n",
      "b_size:10000, l_rate:0.010, epoch:  500:,loss: 0.000000, tr_accuracy: 0.0%, valid_accuracy: 3.3%\n",
      "b_size:10000, l_rate:0.010, epoch: 1000:,loss: 0.000000, tr_accuracy: 0.3%, valid_accuracy: 3.3%\n",
      "b_size:10000, l_rate:0.010, epoch: 1500:,loss: 0.000000, tr_accuracy: 1.8%, valid_accuracy: 3.3%\n",
      "b_size:10000, l_rate:0.010, epoch: 2000:,loss: nan, tr_accuracy: 100.0%, valid_accuracy: 96.7%\n",
      "b_size:10000, l_rate:0.010, epoch: 2500:,loss: nan, tr_accuracy: 100.0%, valid_accuracy: 96.7%\n",
      "b_size:10000, l_rate:0.010, epoch: 3000:,loss: nan, tr_accuracy: 99.4%, valid_accuracy: 96.7%\n",
      "b_size:10000, l_rate:0.010, epoch: 3500:,loss: nan, tr_accuracy: 95.9%, valid_accuracy: 96.7%\n",
      "b_size:10000, l_rate:0.010, epoch: 4000:,loss: nan, tr_accuracy: 100.0%, valid_accuracy: 96.7%\n",
      "b_size:10000, l_rate:0.010, epoch: 4500:,loss: nan, tr_accuracy: 100.0%, valid_accuracy: 96.7%\n",
      "b_size:10000, l_rate:0.010, epoch: 5000:,loss: nan, tr_accuracy: 98.6%, valid_accuracy: 96.7%\n",
      "learning_rate:0.010, Test accuracy: 96.6%\n",
      "optimizer finished\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "learning_rates = [0.01]\n",
    "batch_sizes = [10000]\n",
    "n_epochs = 5001\n",
    "\n",
    "for l_rate in learning_rates:\n",
    "    for batch_size in batch_sizes:\n",
    "        with tf.Session(graph=graph) as sess:\n",
    "            sess.run(init)\n",
    "            saver = tf.train.Saver()\n",
    "        \n",
    "            for epoch in range(n_epochs):\n",
    "                offset = (epoch * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "                batch_data = train_data[offset:(offset + batch_size), :]\n",
    "                batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "                \n",
    "                bias = np.ones([batch_size,1],dtype=np.float32)\n",
    "                \n",
    "                feed_dict = {X: batch_data, Y: batch_labels, L_rate: l_rate, \n",
    "                             X_labels: batch_labels}\n",
    "                o, loss_val, predictions = sess.run([optimizer, loss, train_prediction], feed_dict=feed_dict )\n",
    "                \n",
    "                if epoch % 500 == 0:\n",
    "                    save_path = saver.save(sess, folder + \"tmp/bank_marketing.ckpt\")\n",
    "                    train_accuracy = accuracy(predictions, batch_labels)\n",
    "                    validation_accuracy = accuracy(valid_prediction.eval(), valid_labels)\n",
    "                    print(\"b_size:%5d, l_rate:%.3f, epoch: %4d:,loss: %f, tr_accuracy: %.1f%%, valid_accuracy: %.1f%%\" % \\\n",
    "                          (batch_size,l_rate,epoch,loss_val,train_accuracy,validation_accuracy))\n",
    "        \n",
    "            save_path = saver.save(sess, folder + \"tmp/bank_marketing_final.ckpt\")\n",
    "            \n",
    "            test_accuracy = accuracy(test_prediction.eval(), test_labels)\n",
    "            print(\"learning_rate:%.3f, Test accuracy: %.1f%%\" % (l_rate,test_accuracy))\n",
    "        \n",
    "print(\"optimizer finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
